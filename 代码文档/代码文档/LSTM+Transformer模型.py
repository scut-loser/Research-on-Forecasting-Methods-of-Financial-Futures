import tushare as ts
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import torch
from torch import nn
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# é…ç½®å‚æ•°
DAYS_FOR_TRAIN = 10
EPOCHS = 200
THRESHOLD_SIGMA = 3

# è®¾ç½® Tushare Token
ts.set_token('7c2fa6010f9586a077b7522951abcd8da1f492e09ac05c1678fb0a4e')
pro = ts.pro_api()

# è·å–è‚¡ç¥¨æ•°æ®
df_daily = pro.daily(ts_code='000001.SZ', start_date='20220101', end_date='20240101')
df_daily = df_daily.sort_values('trade_date')
df_close = df_daily[['trade_date', 'close']].rename(columns={'close': 'value'})
df_close['value'] = df_close['value'].astype(float)

# æ•°æ®å½’ä¸€åŒ–
scaler = MinMaxScaler()
data = scaler.fit_transform(df_close[['value']])

# æ„é€ è®­ç»ƒé›†
def create_dataset(data, days=10):
    X, Y = [], []
    for i in range(len(data) - days):
        X.append(data[i:i+days])
        Y.append(data[i+days])
    return np.array(X), np.array(Y)

X, Y = create_dataset(data, DAYS_FOR_TRAIN)
X_tensor = torch.tensor(X, dtype=torch.float32)
Y_tensor = torch.tensor(Y, dtype=torch.float32)

# ========== LSTM æ¨¡å‹ ==========
class LSTM_Regression(nn.Module):
    def __init__(self, input_size, hidden_size, output_size=1, num_layers=2):
        super().__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.linear = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        out, _ = self.lstm(x)
        return self.linear(out[:, -1, :])

lstm_model = LSTM_Regression(1, 64)
lstm_optimizer = torch.optim.Adam(lstm_model.parameters(), lr=0.001)
loss_fn = nn.MSELoss()

# è®­ç»ƒ LSTM
losses = []
for epoch in range(EPOCHS):
    lstm_model.train()
    out = lstm_model(X_tensor)
    loss = loss_fn(out, Y_tensor)
    lstm_optimizer.zero_grad()
    loss.backward()
    lstm_optimizer.step()
    losses.append(loss.item())

# ç»˜åˆ¶ Loss æ›²çº¿
plt.plot(losses)
plt.title("LSTM Training Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.savefig("loss_curve.png")
plt.close()

# LSTM é¢„æµ‹ + åå½’ä¸€åŒ–
lstm_model.eval()
lstm_pred = lstm_model(X_tensor).detach().numpy()
lstm_pred_inv = scaler.inverse_transform(lstm_pred)
true_inv = scaler.inverse_transform(Y_tensor.numpy())

# ========== Transformer æ¨¡å‹ ==========
class TransformerAnomalyDetector(nn.Module):
    def __init__(self, input_dim=1, d_model=64, nhead=4, num_layers=2, dim_feedforward=128):
        super().__init__()
        self.embedding = nn.Linear(input_dim, d_model)
        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead,
                                                   dim_feedforward=dim_feedforward, batch_first=True)
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        self.fc = nn.Linear(d_model, 1)

    def forward(self, x):
        x = self.embedding(x)
        x = self.transformer(x)
        return self.fc(x[:, -1, :])

transformer_model = TransformerAnomalyDetector()
transformer_optimizer = torch.optim.Adam(transformer_model.parameters(), lr=0.001)

# è®­ç»ƒ Transformer
for epoch in range(EPOCHS):
    transformer_model.train()
    pred = transformer_model(X_tensor)
    loss = loss_fn(pred, Y_tensor)
    transformer_optimizer.zero_grad()
    loss.backward()
    transformer_optimizer.step()

# Transformer é¢„æµ‹
transformer_model.eval()
with torch.no_grad():
    tf_pred = transformer_model(X_tensor).numpy()
    tf_pred_inv = scaler.inverse_transform(tf_pred)

# ========== è¯„ä¼°å‡½æ•° ==========
def evaluate(y_true, y_pred, name):
    mse = mean_squared_error(y_true, y_pred)
    mae = mean_absolute_error(y_true, y_pred)
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
    r2 = r2_score(y_true, y_pred)
    print(f"ğŸ“Š {name} æ¨¡å‹è¯„ä¼°:")
    print(f" - MSE  : {mse:.4f}")
    print(f" - MAE  : {mae:.4f}")
    print(f" - MAPE : {mape:.2f}%")
    print(f" - RÂ²   : {r2:.4f}\n")
    return mse, mae, mape, r2

evaluate(true_inv, lstm_pred_inv, "LSTM")
evaluate(true_inv, tf_pred_inv, "Transformer")

# ========== å¼‚å¸¸æ£€æµ‹ä¸ä¿å­˜ ==========
def detect_anomaly(pred_inv, model_name):
    residual = true_inv - pred_inv
    mean_r = residual.mean()
    std_r = residual.std()
    up = mean_r + THRESHOLD_SIGMA * std_r
    down = mean_r - THRESHOLD_SIGMA * std_r
    anomaly = (residual < down) | (residual > up)

    result = pd.DataFrame({
        'date': df_close['trade_date'].values[DAYS_FOR_TRAIN:],
        'true': true_inv.flatten(),
        'predicted': pred_inv.flatten(),
        'residual': residual.flatten(),
        'is_anomaly': anomaly.flatten().astype(int)
    })

    csv_name = f"anomaly_detection_result_{model_name}.csv"
    img_name = f"anomaly_visualization_{model_name}.png"
    result.to_csv(csv_name, index=False)

    # å¯è§†åŒ–
    plt.figure(figsize=(10, 4))
    plt.plot(result['true'], label='True')
    plt.plot(result['predicted'], label='Predicted')
    plt.scatter(result.index[result['is_anomaly'] == 1],
                result['true'][result['is_anomaly'] == 1],
                color='red', label='Anomaly', marker='x')
    plt.title(f"Detected Anomalies - {model_name}")
    plt.legend()
    plt.savefig(img_name)
    plt.close()

    print(f"âœ… {model_name} å¼‚å¸¸æ£€æµ‹å®Œæˆï¼Œå·²ä¿å­˜ï¼š{csv_name}, {img_name}")

detect_anomaly(lstm_pred_inv, "lstm")
detect_anomaly(tf_pred_inv, "transformer")

print("ğŸ“ æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼Œæ‰€æœ‰å›¾åƒå’ŒCSVæ–‡ä»¶å·²ä¿å­˜ã€‚")
